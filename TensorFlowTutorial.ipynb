{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a computational graph\n",
    "\n",
    "Tensorflow programmes involve building a computational graph `tf.Graph` and running this graph using a `tf.Session`\n",
    "\n",
    "This graph is composed of:\n",
    "- `tf.Operation`: The nodes of the graph, that describe calcuations\n",
    "- `tf.Tensor`: The edges of the graph, representing the values that are input and output to the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For representing tensor values, tensorflow uses numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(4, dtype=tf.float32)\n",
    "b = tf.constant(6.0)\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plus_b = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(a_plus_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printing these tensors doesn't output the values. The only thing we did so far was build the computational graph, where \"addition\" was the computation. \n",
    "\n",
    "Each operation in the graph is given a name (independent of the name of the object you give in python). Here, the output tensor of the addition operation is named after the operation that produced it: `add:0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a session\n",
    "To get the actual output values of our computation, we need to create and run a session. As input argument to the run() function, we give the tensor that we want to evaluate. \n",
    "\n",
    "When you request the output of a specific node, tensorflow goes back through the graph and runs all nodes that provide input to that node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(a_plus_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also evaluate multiple tensors, using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run({'a, b':(a, b), 'sum':a_plus_b}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the graph\n",
    "\n",
    "As graphs get bigger it becomes more difficult to keep track of what's happening. But we can visualise the graph using tensorboard. In order to do so, we need to save the computation graph to a tensorboard summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce a file `events.out.tfevents.{timestamp}.{hostname}`\n",
    "\n",
    "Next go to terminal and start tensorboard with:\n",
    "```\n",
    "tensorboard --logdir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data into the graph\n",
    "For feeding values into the computational graph, tensorflow uses \"place holders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "xplusy = (y + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(xplusy, feed_dict= {x: [1., 1., 1.,1.], y: [4.5, 5., 2.,2.]} ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [\n",
    "    [0, 1,],\n",
    "    [2, 3,],\n",
    "    [4, 5,],\n",
    "    [6, 7,],\n",
    "]\n",
    "\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "next_item = slices.make_one_shot_iterator().get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_item))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding trainable parameters to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some training data\n",
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "y_pred = linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "To make these predictions better we want to train the weights in our model.\n",
    "\n",
    "First, we need to define a loss function. Let's use mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Tensorflow comes wiht a set of optimizers, subclasses of `tf.train.Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = []\n",
    "for i in range(100):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  loss_vals.append(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Label'] = np.sort(np.unique(train_labels))\n",
    "df['Class'] = class_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale images\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the layers \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0]) == test_labels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  \n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1]) \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions,  test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions,  test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "In [ ]:\n",
    "\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicitly placing operations on GPU versus CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Forcing CPU computation: \n",
    "\n",
    "n_loops = 2\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_loops):\n",
    "    with tf.Session() as sess:\n",
    "        with tf.device('/cpu:0'): # swap for 'cpu:0' or whatever\n",
    "            a = tf.random_uniform([1000, 1000], name='a')\n",
    "            b = tf.random_uniform([1000, 1000], name='b')            \n",
    "            c = tf.matmul(a, b)\n",
    "            d = tf.matmul(a, c)\n",
    "            for _ in range(1000):\n",
    "                sess.run(d)\n",
    "end = time.time()\n",
    "print('CPU: ')\n",
    "print(\"{} loops: {:0.2f}s\".format(n_loops, end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing GPU computation: \n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_loops):\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        with tf.device('/gpu:0'): # swap for 'cpu:0' or whatever\n",
    "            a = tf.random_uniform([1000, 1000], name='a')\n",
    "            b = tf.random_uniform([1000, 1000], name='b')            \n",
    "            c = tf.matmul(a, b)\n",
    "            d = tf.matmul(a, c)\n",
    "            for _ in range(1000):\n",
    "                sess.run(d)\n",
    "end = time.time()\n",
    "\n",
    "print('GPU: ')\n",
    "print(\"{} loops: {:0.2f}s\".format(n_loops, end - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Debugger\n",
    "\n",
    "Debugging tensorflow code isn't as straightforward as just setting breakpoints, because the computations are only executed when we run a session. \n",
    "\n",
    "The tensorflow debugger `tfdbg` is a specialised debugger for tensorflow.\n",
    "\n",
    "Example from tensorflow website:\n",
    "https://www.tensorflow.org/guide/debugger\n",
    "\n",
    "Run in terminal: \n",
    "\n",
    "```\n",
    "python ~/Projects/tensorflow-tutorial/debug_mnist.py \n",
    "```\n",
    "\n",
    "```\n",
    "Accuracy at step 0: 0.1113\n",
    "Accuracy at step 1: 0.306\n",
    "Accuracy at step 2: 0.098\n",
    "Accuracy at step 3: 0.098\n",
    "Accuracy at step 4: 0.098\n",
    "Accuracy at step 5: 0.098\n",
    "Accuracy at step 6: 0.098\n",
    "Accuracy at step 7: 0.098\n",
    "Accuracy at step 8: 0.098\n",
    "Accuracy at step 9: 0.098\n",
    "```\n",
    "\n",
    "The accuracy goes down and gets stuck at chance level. \n",
    "\n",
    "Sometimes, this happens because sme nodes output bad numeric values such as infs and nans. To investigate this, we can activate tfdb CLI (command line interface) by wrappin the Session object with a debugger wrapper:\n",
    "\n",
    "```\n",
    "\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "\n",
    "```\n",
    "\n",
    "This wrapper allows us to bring up a CLI before and after each `Session.run()` call, so that we can control the execution (like a break point) and inspect the states of nodes in the graph. \n",
    "It also allows you to make and use special filters for tensor values, to facilitate the diagnosis of issues. \n",
    "\n",
    "We're know going to use an inbuilt filter called `tfdbg.has_inf_or_nan` to check for nans and infs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in terminal\n",
    "\n",
    "```\n",
    "python ~/Projects/tensorflow-tutorial/debug_mnist.py --debug\n",
    "```\n",
    "\n",
    "To find infs and nans (the command lt means list dumped tensors):\n",
    "\n",
    "```\n",
    "lt -f has_inf_or_nan\n",
    "```\n",
    "\n",
    "View the value of the tensor:\n",
    "```\n",
    "tfdbg> pt cross_entropy/Log:0\n",
    "```\n",
    "\n",
    "\n",
    "Get a numeric summary:\n",
    "```\n",
    "tfdbg> pt --numeric_summary cross_entropy/Log:0\n",
    "```\n",
    "\n",
    "Why did these minus infinities appear? To further debug, we can display `node_info` using the `ni` command:\n",
    "\n",
    "```\n",
    "tfdbg> ni cross_entropy/Log\n",
    "```\n",
    "\n",
    "From which we see that the node is of type `Log` and that its input is the `Softmax` node. Next, we can look at the input tensor: \n",
    "\n",
    "```\n",
    "tfdbg> pt Softmax:0\n",
    "```\n",
    "\n",
    "We can examine the values in the input tensor: searching for zeros:\n",
    "```\n",
    "tfdbg> /0\\.000\n",
    "```\n",
    "\n",
    "Given that there are indeed zeros, we now know that the origin of the bad numerical valuees is that the node `cross_entropy/Log` takes logs of zeros. We can find the corresponding line in the Python file, using the `-t` flag of the `ni` command to show the traceback of the node's construction:\n",
    "\n",
    "```\n",
    "tfdbg> ni -t cross_entropy/Log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the problem:\n",
    "\n",
    "To fix the problem, we change the line: \n",
    "\n",
    "```\n",
    "diff = -(y_ * tf.log(y))\n",
    "```\n",
    "\n",
    "to the built in numerically stable implimentation of softmax cross entropy:\n",
    "```\n",
    "diff = tf.losses.softmax_cross_entropy(labels=y_, logits=logits)\n",
    "```\n",
    "\n",
    "And then we can rerun the python script to see if the problem persists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
